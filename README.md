# ViFact: Vietnamese Fact-Checking System

ViFact l√† h·ªá th·ªëng ki·ªÉm ch·ª©ng th√¥ng tin t·ª± ƒë·ªông end-to-end d√†nh cho ti·∫øng Vi·ªát. H·ªá th·ªëng k·∫øt h·ª£p c√°c k·ªπ thu·∫≠t truy h·ªìi lai, suy lu·∫≠n ƒëa b∆∞·ªõc v√† sinh gi·∫£i th√≠ch ƒë·ªÉ cung c·∫•p ƒë√°nh gi√° ch√≠nh x√°c v√† ƒë√°ng tin c·∫≠y.

## üåü T√≠nh nƒÉng ch√≠nh

- Truy h·ªìi lai (Hybrid Retrieval): k·∫øt h·ª£p BM25, bi-encoder v√† cross-encoder
- Suy lu·∫≠n ƒëa b∆∞·ªõc: t·ªïng h·ª£p th√¥ng tin t·ª´ nhi·ªÅu b·∫±ng ch·ª©ng
- Sinh gi·∫£i th√≠ch: t·∫°o l·ªùi gi·∫£i th√≠ch trung th·ª±c, c√≥ th·ªÉ truy xu·∫•t
- Ng∆∞·ª°ng tin c·∫≠y th√≠ch nghi: ƒëi·ªÅu ch·ªânh ƒë·ªô tin c·∫≠y theo mi·ªÅn/b·ªëi c·∫£nh
- G·∫Øn nh√£n ngu·ªìn: tr√≠ch d·∫´n r√µ r√†ng v√† ph√°t hi·ªán ph·∫£n ch·ª©ng

## üß± Ki·∫øn tr√∫c h·ªá th·ªëng (kh√°i qu√°t)

```
ViFact/
‚îú‚îÄ‚îÄ vifact/
‚îÇ   ‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retrieval/       # BM25, Dense, Hybrid, Reranker
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confidence/      # Hi·ªáu chu·∫©n & ng∆∞·ª°ng
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rationale/       # Tr√≠ch xu·∫•t lu·∫≠n c·ª© (QATC)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reasoner/        # H·ª£p nh·∫•t ƒëa b·∫±ng ch·ª©ng
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ explainer/       # Sinh gi·∫£i th√≠ch
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ attribution/     # G·∫Øn nh√£n ngu·ªìn
‚îÇ   ‚îú‚îÄ‚îÄ data/                # Loader, ti·ªÅn x·ª≠ l√Ω, validate
‚îÇ   ‚îú‚îÄ‚îÄ utils/               # Logging, ti·ªán √≠ch
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # C·∫•u h√¨nh
‚îÇ   ‚îî‚îÄ‚îÄ cli.py               # L·ªánh x·ª≠ l√Ω d·ªØ li·ªáu
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # D·ªØ li·ªáu th√¥ (append-only)
‚îÇ   ‚îú‚îÄ‚îÄ processed/           # D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω (shards)
‚îÇ   ‚îî‚îÄ‚îÄ corpus/              # Corpus vƒÉn b·∫£n
‚îú‚îÄ‚îÄ config/                  # YAML c·∫•u h√¨nh
‚îú‚îÄ‚îÄ models/                  # Ch·ªâ m·ª•c/ m√¥ h√¨nh ƒë√£ build
‚îî‚îÄ‚îÄ scripts/                 # Ti·ªán √≠ch pipeline
```

## üì¶ D·ªØ li·ªáu

- ViFactCheck: 7,232 c·∫∑p tuy√™n b·ªë‚Äìb·∫±ng ch·ª©ng
- ViWikiFC: Wikipedia ti·∫øng Vi·ªát (>20k tuy√™n b·ªë)
- Vietnamese News Corpus: kho vƒÉn b·∫£n b√°o ch√≠
- VLSP Datasets: b·ªï sung NLI, MRC

## üöÄ B·∫Øt ƒë·∫ßu nhanh

### Y√™u c·∫ßu h·ªá th·ªëng
- Python 3.8+
- PyTorch 1.9+
- Transformers 4.20+
- CUDA 11.0+ (khuy·∫øn ngh·ªã)

### C√†i ƒë·∫∑t

```bash
# Clone repository
git clone https://github.com/your-username/vifact.git
cd vifact

# C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt

# Ho·∫∑c c√†i ƒë·∫∑t t·ª´ source
pip install -e .
```

### Demo nhanh (minh h·ªça)

```bash
# Ch·∫°y demo ki·ªÉm tra c√†i ƒë·∫∑t
python demo.py

# Ho·∫∑c s·ª≠ d·ª•ng CLI
vifact demo
```

### S·ª≠ d·ª•ng c∆° b·∫£n (minh h·ªça)

#### 1. Python API

```python
from vifact import ViFact, ViFactConfig

config = ViFactConfig.from_yaml("config/vifact_config.yaml")
vifact = ViFact(config)
vifact.load_modules()
vifact.load_data()

claim = "Vi·ªát Nam c√≥ 54 d√¢n t·ªôc."
result = vifact.verify(claim)

print(f"Verdict: {result.verdict}")
print(f"Confidence: {result.confidence:.3f}")
print(f"Explanation: {result.explanation}")
print(f"Sources: {len(result.sources)} sources found")
```

#### 2. Command Line

```bash
vifact verify "Vi·ªát Nam c√≥ 54 d√¢n t·ªôc."
vifact train --data-path data/raw/ise-dsc01-warmup.json --epochs 10
vifact evaluate --model-path models/vifact-trained
```

### Hu·∫•n luy·ªán & ƒë√°nh gi√° (minh h·ªça)

```bash
python train.py --config config/vifact_config.yaml --epochs 10
vifact train --epochs 10 --batch-size 16

python evaluate.py --model-path models/vifact-trained
vifact evaluate --model-path models/vifact-trained
```

## üìà K·∫øt qu·∫£ d·ª± ki·∫øn

| Metric | ViFact-Base | ViFact-Large |
|--------|-------------|--------------|
| Accuracy | 85.2% | 88.7% |
| Evidence Recall | 92.1% | 94.3% |
| Faithfulness | 89.4% | 91.8% |

## ‚öôÔ∏è C·∫•u h√¨nh

H·ªá th·ªëng d√πng YAML ƒë·ªÉ ƒëi·ªÅu ch·ªânh tham s·ªë (xem th√™m trong `config/vifact_config.yaml`).

```yaml
# config/vifact_config.yaml
system:
  name: "ViFact"
  version: "0.1.0"
  device: "auto"
```

### C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng ph√°t tri·ªÉn

```bash
# Clone v√† c√†i ƒë·∫∑t
git clone https://github.com/your-username/vifact.git
cd vifact

# C√†i ƒë·∫∑t dependencies ph√°t tri·ªÉn
pip install -r requirements.txt
pip install -e ".[dev]"

# Ch·∫°y tests
pytest tests/

# Format code (n·∫øu d√πng)
black vifact/
flake8 vifact/
```

### Roadmap ph√°t tri·ªÉn

Xem [ROADMAP.md](ROADMAP.md) ƒë·ªÉ bi·∫øt k·∫ø ho·∫°ch chi ti·∫øt.

## üìö Tr√≠ch d·∫´n

```bibtex
@article{vifact2026,
  title={ViFact: An End-to-End Vietnamese Fact-Checking System with Explainable Multi-Step Reasoning},
  author={Your Name and Collaborators},
  journal={Conference/Journal Name},
  year={2026}
}
```

## üìù Gi·∫•y ph√©p

MIT License - xem file `LICENSE` ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.

## ü§ù ƒê√≥ng g√≥p

Ch√∫ng t√¥i hoan ngh√™nh m·ªçi ƒë√≥ng g√≥p! Vui l√≤ng:

1. Fork repository
2. T·∫°o feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. T·∫°o Pull Request

## üì´ Li√™n h·ªá

- Email: your.email@domain.com
- GitHub Issues: [Link to issues page]
- Documentation: [Link to docs]

## üôè Acknowledgments

- ViFactCheck dataset creators
- Vietnamese NLP community
- Open source contributors

## üîß Chu·∫©n b·ªã d·ªØ li·ªáu cho Retrieval (Phase 1)

C√°c b∆∞·ªõc ng·∫Øn g·ªçn ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn, x√¢y corpus v√† ch·ªâ m·ª•c:

1) Ti·ªÅn x·ª≠ l√Ω + chia nh·ªè (sharding)

```bash
python -m vifact.cli process \
  --input data/raw/ise-dsc01-warmup.json \
  --output data/processed \
  --skip-invalid
```

2) T·∫°o splits

```bash
python -m vifact.cli split \
  --input data/processed \
  --output data/processed/splits \
  --train 0.8 --val 0.1 --seed 42
```

3) X√¢y corpus vƒÉn b·∫£n (d√πng cho indexing)

```bash
python scripts/build_corpus.py \
  --input data/processed \
  --output data/corpus/docs.jsonl
```

4) Ch·ªâ m·ª•c BM25 v√† Dense

```bash
# BM25
python scripts/build_index.py \
  --corpus data/corpus/docs.jsonl \
  --output models/bm25.pkl.gz

# Dense bi-encoder
python scripts/build_dense_index.py \
  --corpus data/corpus/docs.jsonl \
  --output models/dense_index.npz
```

5) Ki·ªÉm tra retrieval nhanh

```bash
# BM25 / Dense / Hybrid
python scripts/retrieval_eval.py --mode bm25  --index models/bm25.pkl.gz           --data data/processed --k 10 --limit 1000
python scripts/retrieval_eval.py --mode dense  --dense-index models/dense_index.npz --data data/processed --k 10 --limit 1000
python scripts/retrieval_eval.py --mode hybrid --index models/bm25.pkl.gz --dense-index models/dense_index.npz --data data/processed --k 10 --limit 1000
```

G·ª£i √Ω: D√πng `JSONL` + `ijson` ƒë·ªÉ stream d·ªØ li·ªáu l·ªõn; ƒë·∫∑t file g·ªëc ·ªü `data/raw/` (append-only), chu·∫©n h√≥a Unicode (UTF-8, NFKC). Tinh ch·ªânh tham s·ªë trong `config/vifact_config.yaml` (`retrieval.bm25.k1/b`, `retrieval.dense.model_name/batch_size`).

## ‚úÖ Ti√™u ch√≠ ho√†n th√†nh ti·ªÅn x·ª≠ l√Ω

- Schema h·ª£p l·ªá: kh√¥ng c√≤n l·ªói thi·∫øu tr∆∞·ªùng (`claim/context/verdict`), `verdict ‚àà {SUPPORTED, REFUTED, NEI}`.
- Shards s·∫µn s√†ng: c√≥ `data/processed/shard_*.jsonl`, ƒë·∫øm b·∫£n ghi kh·ªõp (tr·ª´ record b·ªã b·ªè qua).
- Splits ƒë·ªß: `train/val/test.jsonl` ph√¢n ph·ªëi h·ª£p l√Ω.
- Corpus nh·∫•t qu√°n: `data/corpus/docs.jsonl` g·ªìm `doc_id,text`, tr√πng l·∫∑p th·∫•p.
- Index s·∫µn s√†ng: `models/bm25.pkl.gz` v√†/ho·∫∑c `models/dense_index.npz` t·∫°o th√†nh c√¥ng (N, avgdl h·ª£p l√Ω).
- Sanity-check: `recall@10` v√† `mrr` > 0 tr√™n m·∫´u ki·ªÉm tra; kh√¥ng l·ªói runtime.

## üõ°Ô∏è Confidence: Hi·ªáu chu·∫©n & Ng∆∞·ª°ng (Phase 2)

Chu·∫©n ho√° x√°c su·∫•t v√† ƒë·∫∑t ng∆∞·ª°ng t·ª± tin (abstain ‚Üí NEI) ƒë·ªÉ gi·∫£m d·ª± ƒëo√°n sai khi ƒë·ªô tin c·∫≠y th·∫•p.

1) Hi·ªáu chu·∫©n nhi·ªát ƒë·ªô (Temperature Scaling)

```bash
python scripts/confidence_calibrate.py \
  --preds data/val_preds.jsonl \
  --out models/confidence/calibration.json \
  --labels SUPPORTED REFUTED NEI
```

2) T·ªëi ∆∞u ng∆∞·ª°ng tin c·∫≠y (to√†n c·ª•c + theo domain)

```bash
python scripts/confidence_tune.py \
  --preds data/val_preds.jsonl \
  --out models/confidence/thresholds.json \
  --labels SUPPORTED REFUTED NEI \
  --metric f1 \
  --calibration-json models/confidence/calibration.json
```

3) √Åp d·ª•ng v√†o d·ª± ƒëo√°n (s·∫£n xu·∫•t/test)

```bash
python scripts/confidence_apply.py \
  --preds data/test_preds.jsonl \
  --out data/test_preds_final.jsonl \
  --labels SUPPORTED REFUTED NEI \
  --calibration-json models/confidence/calibration.json \
  --thresholds-json models/confidence/thresholds.json
```

ƒê·∫ßu v√†o d·ª± ƒëo√°n (`*.jsonl`): m·ªói d√≤ng c·∫ßn `id`, (tu·ª≥ ch·ªçn) `domain`, v√† `logits` ho·∫∑c `probs`. Khi calibrate/tune n√™n c√≥ th√™m `label` ƒë·ªÉ t√≠nh ECE/NLL/Brier.

### üí° M·∫πo m√£ h√≥a (Windows)
- N√™n d√πng UTF-8 ƒë·ªÉ hi·ªÉn th·ªã ti·∫øng Vi·ªát ch√≠nh x√°c trong PowerShell:
  - `chcp 65001`
  - `$OutputEncoding = [Console]::OutputEncoding = [Text.UTF8Encoding]::new()`

## üß† Rationale & Explanation (Phase 2)

Hu·∫•n luy·ªán tr√≠ch xu·∫•t rationale (c√¢u) v√† t·∫°o l·ªùi gi·∫£i th√≠ch ng·∫Øn k√®m ngu·ªìn.

- Train tr√™n Colab: xem `PHASE2_COLAB.md`
- D·ª± ƒëo√°n rationale:

```bash
python scripts/predict_rationale.py \
  --data data/processed \
  --model /path/to/rationale_model \
  --out data/processed/rationales.jsonl \
  --topk 2
```

- T·∫°o explanation v·ªõi retrieval + rationale:

```bash
python scripts/generate_explanations.py \
  --data data/processed \
  --out data/processed/explanations.jsonl \
  --bm25-index models/bm25.pkl.gz \
  --dense-index models/dense_index.npz \
  --rationales data/processed/rationales.jsonl \
  --k 5 --k-sparse 150 --k-dense 150 --w-sparse 0.7 --w-dense 0.3
```

- ƒê·∫ßu ra: m·ªói d√≤ng g·ªìm `id, claim, verdict (ground truth), rationale, sources[], explanation`.
